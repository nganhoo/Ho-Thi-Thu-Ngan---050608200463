{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BIG DATA - L14**\n",
        "\n",
        "**NHÓM 10**\n",
        "1. Hồ Thị Thu Ngân - 050608200463\n",
        "2. Bùi Thị Thanh Thảo - 050608200145 "
      ],
      "metadata": {
        "id": "X6O_78wiM0Wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **HOMEWORK 1**"
      ],
      "metadata": {
        "id": "QlRvqqyANjA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CÂU 1**"
      ],
      "metadata": {
        "id": "3flni0WQtmlr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "xWpDiLe_V6pC",
        "outputId": "dfa8cd43-d6a7-4602-e125-847cffcdf005"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.9/dist-packages (3.3.2)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.5)\n",
            "openjdk-8-jdk-headless is already the newest version (8u362-ga-0ubuntu1~20.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Cài đặt Spark \n",
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "d9RBHCCmX-ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Avoids scroll-in-the-scroll in the entire Notebook\n",
        "from IPython.display import Javascript\n",
        "def resize_colab_cell():\n",
        "  display(Javascript('google.colab.output.setIframeHeight(0, true, {maxHeight: 400})'))\n",
        "get_ipython().events.register('pre_run_cell', resize_colab_cell)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TpsEs4A1a2Ob",
        "outputId": "361a7567-49d0-4338-d1f2-a5a65be07dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nhập các thư viện cần dùng \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf "
      ],
      "metadata": {
        "id": "vZ5UmBaPhwUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "50d50cfe-4b0b-4c47-d10c-983fb748ce25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mXIc8MtZlnv3",
        "outputId": "a910fae5-5f28-48a8-f0bf-4b8ccb7b3bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def line2dataset(line):\n",
        "    src, dst_line= line.split('\\t')\n",
        "    src = int(src.strip())\n",
        "    dst_list = [int(x.strip()) for x in dst_line.split(',') if x != '']\n",
        "    return src, dst_list"
      ],
      "metadata": {
        "id": "JnOBKQwCTFpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_pairs(x):\n",
        "    if (x[0][0] != x[1][0]) and (not x[0][0] in x[1][1]) and (not x[1][0] in x[0][1]):\n",
        "        shared = len(list(set(x[0][1]).intersection(set(x[1][1]))))\n",
        "        return (x[0][0],[x[1][0],shared])"
      ],
      "metadata": {
        "id": "PWuMr2oOaJQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_finaldataset(elem):\n",
        "    src = elem[0]\n",
        "    dst_commons = elem[1]\n",
        "    dst_commons=sorted(dst_commons,key=lambda x:(-x[1],x[0]))[:10]\n",
        "    recommendations=[pair[0] for pair in dst_commons]\n",
        "    return (src, recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ai08JeuraMb2",
        "outputId": "4c1ae3f9-ee78-4a51-974c-2d439f74f9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    spark = SparkSession.builder.getOrCreate()\n",
        "    sc = spark.sparkContext\n",
        "    dataset = sc.textFile(\"/content/soc-LiveJournal1Adj.txt\")\n",
        "\n",
        "    dataset = dataset.map(line2dataset)\n",
        "\n",
        "    check_users = [924, 8941, 8942, 9019, 9020, 9021, 9022, 9990, 9992, 9993]\n",
        "    cartesian = dataset.cartesian(dataset).filter(lambda x: x[0][0] in check_users)\n",
        "\n",
        "    dataset = cartesian.map(filter_pairs).filter(lambda x: x != None and x[1][1] > 0)\\\n",
        "        .filter(lambda x: x[0] in check_users) \\\n",
        "        .groupByKey().mapValues(list).map(map_finaldataset)\n",
        "\n",
        "    id_check_dataset = dataset.filter(lambda x: x[0] in check_users).collect()\n",
        "\n",
        "    for key, val in id_check_dataset:\n",
        "        print('id:', key,' recommendations:', val) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "PehR_OsncOgJ",
        "outputId": "c86ed2cc-f141-454f-b205-f0de02a68a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 400})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 9020  recommendations: [9021, 9016, 9017, 9022, 317, 9023]\n",
            "id: 924  recommendations: [439, 2409, 6995, 11860, 15416, 43748, 45881]\n",
            "id: 9992  recommendations: [9987, 9989, 35667, 9991]\n",
            "id: 9021  recommendations: [9020, 9016, 9017, 9022, 317, 9023]\n",
            "id: 9993  recommendations: [9991, 13134, 13478, 13877, 34299, 34485, 34642, 37941]\n",
            "id: 8941  recommendations: [8943, 8944, 8940]\n",
            "id: 9022  recommendations: [9019, 9020, 9021, 317, 9016, 9017, 9023]\n",
            "id: 9990  recommendations: [13134, 13478, 13877, 34299, 34485, 34642, 37941]\n",
            "id: 8942  recommendations: [8939, 8940, 8943, 8944]\n",
            "id: 9019  recommendations: [9022, 317, 9023]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Câu 2**"
      ],
      "metadata": {
        "id": "VQjcnC6ft1kV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Câu a:**\n",
        "\n",
        "*Nhược điểm:* Confidence có sự bất cập là vì nó đã bỏ qua xác suất của Pr(B). Đôi khi Confidence có kết quả cao do tập mục A của luật kết hợp tương đối cao (ví dụ một tiệm tạp hóa bán quá nhiều A nhưng B lại ít thì Confidence tương đối cao), mà không phải do có mối quan hệ giữa 2 tập mục A và B.\n",
        "\n",
        "Theo đề bài, conf(A → B) = Pr(B|A). Trong đó, Pr(B|A) là xác suất có điều kiện của việc tìm thấy B nếu có A, công thức Pr(B|A) = $\\frac{Pr(A ∩ B)}{Pr(A)}$. Ví dụ ta có luật kết hợp A -> B, một tiệm tạp hóa bán 20 mặt hàng A và 100 mặt hàng B trong tổng số 1000 mặt hàng. Nhìn vào tử số thấy được Pr(A ∩ B) = $\\frac{20}{1000}$ và mẫu số Pr(A) = $\\frac{20}{1000}$, nên suy ra Confidence của luật kết hợp này bằng 1 nhưng nó lại không thể hiện mối quan hệ có ý nghĩa giữa mặt hàng A và mặt hàng B, mặt khác nó chỉ cho thấy B xuất hiện nhiều hơn A, mà Pr(B) =$\\frac{100}{1000}$ đã bị bỏ qua trong công thức.\n",
        "\n",
        "Trong khi Lift và Conviction lại có xác suất của cả 2 tập mục A và B trong công thức lift(A → B) = $\\frac{conf(A → B)}{S(B)}$ (conf có Pr(A) và S(B) = Pr(B)), tương tự với công thức conv, conv(A → B) = $\\frac{(1 − S(B)}{1 − conf(A → B)}$. Lấy một ví dụ minh họa về Lift và số liệu từ phần trên thì ta được Lift = 10, tức tỉ lệ 10:1, chứng tỏ A và B có mối quan hệ liên quan với nhau. Điều này giúp cho công thức có thể tránh được vấn đề thiên vị so với Confidence (Confidence đã loại bỏ Pr(B) khỏi công thức)."
      ],
      "metadata": {
        "id": "zGiDcgyRzyfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Câu b:** \n",
        "\n",
        "Lift là đối xứng (luật A→B = luật B→A), còn Confidence và Conviction thì không phải. Ta suy ra từ công thức:\n",
        "\n",
        "lift(A→B) = lift(B→A) = $\\frac{Pr(A ∩ B)}{Pr(A) x Pr(B)}$.\n",
        "\n",
        "1. conf(A→B) = Pr(B|A) và conf(B→A) = Pr(A|B).\n",
        "2. Pr(A|B) và Pr(B|A) có thể khác nhau.\n",
        "3. conv dựa trên conf và có tính định hướng.\n",
        "\n",
        "*Ví dụ:* Nếu ta có các rổ AB, AC, AD, AE thì S(A) = 4/4, S(B) = 1/4 và Pr(A ∩ B) = 1/4. Khi đó conf(A→B) = Pr(B|A) ≠ Pr(A|B) = conf(B→A) vì: ${1/4 \\choose 4/4}$ ≠ $\\frac{1/44}{4}$. Tương tự, conv(A→B) = $\\frac{1 − S(B)}{1 − conf(A→B)}$ ≠ $\\frac{1 − S(A)}{1 − conf(B→A)}$ = conv(B→A) vì: $\\frac{1 − \\frac{1}{4}}{1 − \\frac{1}{4}}$ = 1 # $\\frac{1 − \\frac{4}{4}}{1 − 1}$= inf. Vậy nên, chỉ có công thức Lift thỏa mãn được luật A→B = luật B→A. "
      ],
      "metadata": {
        "id": "t5OmdHae0hiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Câu c:**\n",
        "\n",
        "Conviction và oConfidence thỏa mãn được trong khi Lift thì không. Nếu B xảy ra mỗi thời điểm A xảy ra (nghĩa là Pr(B|A) = 1) thì:\n",
        "\n",
        "1. conf(A→B) = 1\n",
        "2. conv(A→B)→infinity\n",
        "3. lift(A→B) phụ thuộc vào giá trị của Pr(B) và có thể khác vì B có thể xảy ra trong các giỏ không có A. Ví dụ: Nếu chúng ta có các rổ AB, AB, CD, EF thì Pr(B|A) = 1, S(B) = $\\frac{1}{2}$, Pr(D|C) = 1, và S(D) = $\\frac{1}{4}$. Sau đó, lift(A→B) = $\\frac{1}{\\frac{1}{2}}$ = 2 và lift(C→D) = $\\frac{1}{\\frac{1}{4}}$ = 4. Mặc dù cả hai quy tắc đều là quy tắc 100% nhưng chúng có tỉ lệ Lift khác nhau. "
      ],
      "metadata": {
        "id": "BWMEBUdJ04TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from functools import partial\n",
        "from itertools import combinations"
      ],
      "metadata": {
        "id": "AVPuwLmgQJHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Câu d: \n",
        "if __name__=='__main__':\n",
        "    spark = SparkSession.builder.getOrCreate()\n",
        "    sc = spark.sparkContext\n",
        "    lines=sc.textFile('/content/browsing.txt')\n",
        "\n",
        "    frequent_items=lines.flatMap(lambda l:l.split()).map(lambda ele:(ele,1)).\\\n",
        "        reduceByKey(lambda e1,e2:e1+e2).filter(lambda x:x[1]>=100)\n",
        "\n",
        "    frequent_itemset=frequent_items.collectAsMap()\n",
        "\n",
        "    frequent_pairs = lines.map(lambda l: l.split()).flatMap(partial(combinations, r=2)).map(lambda pair: sorted(pair)) \\\n",
        "        .map(lambda pair: (tuple(pair), 1)).filter(\n",
        "        lambda ele: ele[0][0] in frequent_itemset and ele[0][1] in frequent_itemset).reduceByKey(\n",
        "        lambda p1, p2: p1 + p2).filter(lambda x: x[1] >= 100)\n",
        "\n",
        "    freq_pairs_count=frequent_pairs.collectAsMap()\n",
        "\n",
        "    frequent_pairs=frequent_pairs.flatMap(lambda ele:[((ele[0][0],ele[0][1]),ele[1]),((ele[0][1],ele[0][0]),ele[1])])\n",
        "\n",
        "    frequent_pair_conf=frequent_pairs.map(lambda ele:(ele[0],float(ele[1]/frequent_itemset[ele[0][0]]))).sortBy(lambda x:-x[1])\n",
        "\n",
        "    frequent_pair_conf.toDF().show(10) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k_XE1P4QQ_8",
        "outputId": "3692b90a-8226-4ee4-cb16-9b2e720b11ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|                  _1|                _2|\n",
            "+--------------------+------------------+\n",
            "|{DAI93865, FRO40251}|               1.0|\n",
            "|{GRO85051, FRO40251}| 0.999176276771005|\n",
            "|{GRO38636, FRO40251}|0.9906542056074766|\n",
            "|{ELE12951, FRO40251}|0.9905660377358491|\n",
            "|{DAI88079, FRO40251}|0.9867256637168141|\n",
            "|{FRO92469, FRO40251}| 0.983510011778563|\n",
            "|{DAI43868, SNA82528}| 0.972972972972973|\n",
            "|{DAI23334, DAI62779}|0.9545454545454546|\n",
            "|{ELE92920, DAI62779}|0.7326649958228906|\n",
            "|{DAI53152, FRO40251}| 0.717948717948718|\n",
            "+--------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Câu e: \n",
        "triples=lines.map(lambda l:l.split()).flatMap(partial(combinations,r=3)).map(lambda triple:tuple(list(sorted(triple))))\n",
        "\n",
        "triples=triples.map(lambda triple:(triple,1)).reduceByKey(lambda t1,t2:t1+t2).filter(lambda x:x[1]>=100)\n",
        "\n",
        "freq_triples_conf=triples.flatMap(lambda ele:[(((ele[0][0],ele[0][1]),ele[0][2]),ele[1]),\n",
        "                                                  (((ele[0][0],ele[0][2]),ele[0][1]),ele[1]),\n",
        "                                                  (((ele[0][1],ele[0][2]),ele[0][0]),ele[1])])\\\n",
        ".reduceByKey(lambda t1,t2:t1+t2).map(lambda ele:(ele[0],ele[1]/freq_pairs_count[ele[0][0]])).sortBy(lambda x:(-x[1],x[0][0],x[0][1]))\\\n",
        "                        .map(lambda ele:(ele[0][0],ele[0][1],ele[1]))\n",
        "freq_triples_conf.toDF().show(10) \n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieE8uCNZRuST",
        "outputId": "283f74aa-c0ac-4149-b092-6a956b6f3382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+---+\n",
            "|                  _1|      _2| _3|\n",
            "+--------------------+--------+---+\n",
            "|{DAI23334, ELE92920}|DAI62779|1.0|\n",
            "|{DAI31081, GRO85051}|FRO40251|1.0|\n",
            "|{DAI55911, GRO85051}|FRO40251|1.0|\n",
            "|{DAI62779, DAI88079}|FRO40251|1.0|\n",
            "|{DAI75645, GRO85051}|FRO40251|1.0|\n",
            "|{ELE17451, GRO85051}|FRO40251|1.0|\n",
            "|{ELE20847, FRO92469}|FRO40251|1.0|\n",
            "|{ELE20847, GRO85051}|FRO40251|1.0|\n",
            "|{ELE26917, GRO85051}|FRO40251|1.0|\n",
            "|{FRO53271, GRO85051}|FRO40251|1.0|\n",
            "+--------------------+--------+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Câu 3**"
      ],
      "metadata": {
        "id": "jyXBgjaxxWfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Câu a, b:**\n",
        "\n",
        "Giả sử chúng ta muốn xác suất “don't know” tối đa là  e−10 . Giả sử n và m đều rất lớn (nhưng n lớn hơn nhiều so với m hoặc k), hãy đưa ra một xấp xỉ đơn giản cho giá trị nhỏ nhất của k sẽ đảm bảo xác suất này tối đa là  e−10 . Biểu hiện của bạn nên là một hàm của n và m."
      ],
      "metadata": {
        "id": "-7zod9c7a6MY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Số cột có m phần tử 1 trên tổng số n cột là ${n \\choose m}$. Số lượng cột đó mà không có số 1 trong & hàng được chọn là ${n-k \\choose m}$.\n",
        "Xác suất để chọn được cột đó là: $\\displaystyle\\frac{n-k \\choose m}{n \\choose m}$.\n",
        "Do đó, xác suất để đạt được \"don't know\" khi minhashing cho cột đó là 1 trên tổng số ${n \\choose m}$ trường hợp cột, tức là:\n",
        "\n",
        "P(don't know)=${\\displaystyle\\frac{(n-k) \\choose m}{n\\choose m}}$ + $\\displaystyle\\frac{(n-k)!m!(n-m)!}{m!(n-k-m)!n!}$+ $\\displaystyle\\frac{(n-k)*(n-k-1)...(n-k-m+1)} {n*(n-1)...(n-m+1)}$\n",
        "Để giới hạn xác suất này, ta có thể sử dụng bất đẳng thức AM- GM:\n",
        "$\\displaystyle\\frac{(n - k) + (n - k - 1) + \\cdots + (n - k - m + 1)}{m} \\ge \\sqrt[m]{(n - k) * (n - k - 1) \\cdots (n - k - m + 1}$\n",
        "\n",
        "Hay:\n",
        "$(n - k - m + 1)*(n - k - m + 2)\\cdots(n - k) \\le (\\displaystyle\\frac{n - k}{m})^m $n^m$\n",
        "\n",
        "Do đó:\n",
        "\n",
        "$P(\\text{don't know}) = \\displaystyle\\frac{(n -k)*(n -k-1)\\cdots(n -k-m + 1)}{n*(n-1)\\cdots(n-m+1)} \\le (\\displaystyle\\frac{n - k}{n})^m$\n",
        "\n",
        "Vì vậy, xác suất tối đa để đạt được \"don't know\" là $\\left(\\frac{n-k}{n}\\right)^m$.\n",
        "\n",
        "Với giá trị $e^{-10}$, ta có: $(\\displaystyle\\frac{n-k}{n})^m \\le e^{-10}$\n",
        "\n",
        "Tương đương với: $(1 - \\displaystyle\\frac{k}{n})^m \\le e^{-10}$\n",
        "\n",
        "Do $1-x \\le e^{-x}$, ta có: $x^{\\displaystyle\\frac{-km}{n}} = e^{-10}$"
      ],
      "metadata": {
        "id": "oWT18ZsGHP8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Câu c:**"
      ],
      "metadata": {
        "id": "ThbEFvU4ZWhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hai cột (tập hợp) là:\n",
        "\n",
        "$[0  1  0]^{T}$ và $[0  1  1]^{T}$\n",
        "(b) Giá trị hệ số tương đồng Jaccard giữa S1 và S2 là:\n",
        "\n",
        "J(S1, S2) = |S1 ∩ S2| / |S1 ∪ S2| = $\\frac{1}{2}$\n",
        "(c) Xác suất để một hoán vị tuần hoàn ngẫu nhiên cho giá trị minhash giống nhau cho cả S1 và S2 là:\n",
        "\n",
        "P(minhash(S1) = minhash(S2) | cyclic permutations) = $\\frac{2}{3}$\n",
        "\n",
        "Giải thích:\n",
        "\n",
        "Khi chỉ xem xét các hoán vị tuần hoàn, chỉ có ba hoán vị có thể xảy ra: (1,2,3), (2,3,1), và (3,1,2). Nếu chúng ta bắt đầu chu kỳ tại hàng đầu tiên hoặc thứ hai (1 hoặc 2), giá trị minhash của S1 và S2 sẽ giống nhau. Tuy nhiên, nếu chúng ta bắt đầu chu kỳ tại hàng cuối cùng (3), giá trị minhash sẽ khác nhau. Do đó, xác suất của giá trị minhash giống nhau là $\\frac{2}{3}$."
      ],
      "metadata": {
        "id": "JY6qGrDXZeyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Câu 4**"
      ],
      "metadata": {
        "id": "FdcXVEcXt6gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Câu a:** \n",
        "\n",
        "Đối với mỗi 1≤ j ≤ L, chúng ta có:\n",
        "\n",
        "Pr[x∈T∩Wj] ≤ p${k \\choose 2}$ = $\\displaystyle\\frac{1}{n}$,\n",
        "\n",
        "Điều đó có nghĩa là xác suất một điểm dữ liệu bất kỳ x nằm cùng trong T và Wj không quá $\\displaystyle\\frac{1}{n}$. Do đó, chúng ta có thể viết:\n",
        "\n",
        "E[|T ∩ Wj|] = ∑x∈A, Pr[x∈T ∩ Wj] ≤ ∑x∈A, Pr[x∈T] Pr[x∈Wj] ≤ p${k \\choose 2}$ = $\\displaystyle\\frac{1}{n}$.\n",
        "\n",
        "Sử dụng tính tuyến tính của kỳ vọng, chúng ta có:\n",
        " \n",
        "E[∑j=1LE[PLj=1 |T ∩ Wj|]] ≤ LE[|T ∩ Wj|] ≤ $\\displaystyle\\frac{L}{n}$.\n",
        "\n",
        "Bây giờ, chúng ta có thể áp dụng bất đẳng thức Markov để có được:\n",
        "\n",
        "Pr[∑j=1L|T ∩ Wj| > 3L] ≤ E[∑j=1L|T ∩ Wj|]/3L ≤ $\\displaystyle\\frac{1}{3}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "KvwJYOrzvTA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Câu b:**\n",
        "\n",
        "Ta có:\n",
        "\n",
        "Pr[gj($x^{*}$) = gj(z)] ≥ pk1\n",
        "\n",
        "Ta có thể sử dụng bất đẳng thức trên để thu được một giới hạn trên cho xác suất rằng gj($x^{*}$) ≠ gj(z), như sau:\n",
        "\n",
        "Pr[gj($x^{*}$) ≠ gj(z)] ≤ 1 - Pr[gj($x^{*}$) = gj(z)] \n",
        "\n",
        "≤ 1 - pk1\n",
        "\n",
        "= 1 - $p^{\\displaystyle\\frac{log1}{p2(n)}}$) _ 1 (thay thế pk1 bằng định nghĩa của nó) \n",
        "\n",
        "= 1 - $(\\displaystyle\\frac{1}{n})^{\\displaystyle\\frac{log1}{p2(n)}}$\n",
        "\n",
        "= 1 - $(\\displaystyle\\frac{1}{n})^{p}$\n",
        " (với ρ = log($\\displaystyle\\frac{1}{p1}$) / log($\\displaystyle\\frac{1}{p2}$))\n",
        "\n",
        "= 1 - $\\displaystyle\\frac{1}{L}$\n",
        "\n",
        "= $\\displaystyle\\frac{(L-1)}{L}$\n",
        "\n",
        "Trong đó: k = $\\displaystyle\\frac{log1}{p2(n)}$, do đó L = $n^{p}$.\n",
        "\n",
        "Tiếp theo, ta có thể sử dụng bất đẳng thức trên để thu được một giới hạn trên cho xác suất rằng tất cả các gj đều thỏa mãn gj($x^{*}$) ≠ gj(z), như sau:\n",
        "\n",
        "Pr [∀ 1 ≤ j ≤ L, gj($x^{*}$) ≠ gj(z)] \n",
        "\n",
        "≤ ∏_{j=1}^L Pr[gj($x^{*}$) ≠ gj(z)] (sử dụng kết hợp liên minh) \n",
        "\n",
        "≤ $(\\displaystyle\\frac{L-1}{L})^{L}$ \n",
        "\n",
        "≤ $e^{-1}$ = $\\displaystyle\\frac{1}{e}$ "
      ],
      "metadata": {
        "id": "EACCGE2Yv-uA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Câu c:**\n",
        "\n",
        "Giả sử $x^{*}$ là hàng xóm gần nhất thực sự với điểm truy vấn z với khoảng cách d ($x^{*}$, z) ≤ λ. Từ phần (b), chúng ta biết rằng với xác suất ít nhất là 1 - $\\displaystyle\\frac{1}{e}$, $x^{*}$ được băm vào ít nhất một trong L thùng mà điểm truy vấn băm vào, tức là tồn tại một hàm băm gj sao cho gj ($x^{*}$) = gj (z).\n",
        "Bây giờ, hãy để Wj là tập hợp các điểm dữ liệu được ánh xạ đến cùng một thùng như điểm truy vấn z bằng cách sử dụng hàm băm gj, như được định nghĩa trong phần (a). Hãy để T là tập hợp các điểm dữ liệu cách điểm truy vấn xa hơn cλ. Từ phần (a), chúng ta biết rằng xác suất của ít nhất 3L điểm dữ liệu nằm trong phần giao của T và Wj cho một số j nhỏ hơn hoặc bằng $\\displaystyle\\frac{1}{3}$.\n",
        "\n",
        "Giả sử rằng $x^{*}$ được băm vào ít nhất một trong L thùng mà điểm truy vấn băm vào, chúng ta cần xem xét hai trường hợp:\n",
        "\n",
        "Trường hợp 1: $x^{*}$ không nằm trong phần giao của T và bất kỳ Wj nào. Trong trường hợp này, thuật toán sẽ trả về $x^{*}$, đó là hàng xóm gần nhất thực sự với điểm truy vấn với khoảng cách d ($x^{*}$, z) ≤ λ.\n",
        "\n",
        "Trường hợp 2: $x^{*}$ nằm trong phần giao của T và một số Wj. Trong trường hợp này, thuật toán có thể trả về một điểm không phải là hàng xóm gần nhất thực sự với điểm truy vấn. Tuy nhiên, xác suất của việc này có thể được giới hạn như sau:\n",
        "Giả sử Yj là biến chỉ mục có giá trị bằng 1 nếu có ít nhất 3 điểm dữ liệu nằm trong giao của T và Wj, và bằng 0 nếu không. Khi đó, xác suất thất bại của thuật toán có thể được biểu diễn như sau:\n",
        "Pr[thuật toán thất bại] = Pr[$x^{*}$ nằm trong giao của T và một số Wj] × Pr[thuật toán chọn một điểm không phải $x^{*}$ từ giao này]\n",
        "Sử dụng bất đẳng thức liên hợp và kết quả từ phần (a), ta có:\n",
        "Pr[$x^{*}$ nằm trong giao của T và một số Wj] ≤ Σj Pr[Yj = 1] ≤ Σj Pr[3L điểm dữ liệu nằm trong T và Wj] ≤ L($\\displaystyle\\frac{1}{3}$) = ρlog($\\displaystyle\\frac{1}{p1}$)\n",
        "Ở đây, bất đẳng thức cuối cùng được suy ra từ định nghĩa của ρ trong thủ tục.\n",
        "Giờ đây, giả sử Zj là biến chỉ mục có giá trị bằng 1 nếu thuật toán chọn một điểm không phải $x^{*}$ từ giao của T và Wj, và bằng 0 nếu không. Khi đó, xác suất chọn một điểm không phải $x^{*}$ từ giao của T và Wj có thể được biểu diễn như sau:\n",
        "Pr[thuật toán chọn một điểm không phải $x^{*}$ từ giao này] = Σj Pr[Zj = 1]\n",
        "Vì các điểm dữ liệu được chọn đồng đều ngẫu nhiên từ giao của T và Wj, nên xác suất chọn một điểm không phải $x^{*}$ bị chặn dưới bởi (|T ∩ Wj| - 1) / |T ∩ Wj|. Do đó, ta có:\n",
        "Pr[Zj = 1] ≤ (|T ∩ Wj| - 1) / |T ∩ Wj| ≤ 1 - 1/|T ∩ Wj|\n",
        "Sử dụng bất đẳng thức liên hợp một lần nữa, ta có:\n",
        "Pr[thuật toán thất bại] ≤ Pr[$x^{*}$ nằm trong giao của T và một số Wj] × Pr[thuật toán chọn một điểm không phải $x^{*}$ từ giao này]"
      ],
      "metadata": {
        "id": "d3RnwWHqw1rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#import random\n",
        "import time\n",
        "#import pdb\n",
        "import unittest\n",
        "from PIL import Image\n",
        "\n",
        "def l1(u, v):\n",
        "    return  np.abs(u-v).sum()"
      ],
      "metadata": {
        "id": "2K4rJ-AaVNNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filename):\n",
        "    return np.genfromtxt(filename, delimiter=',')\n",
        "\n",
        "def create_function(dimensions, thresholds):\n",
        "    def f(v):\n",
        "        boolarray = [v[dimensions[i]] >= thresholds[i] for i in range(len(dimensions))]\n",
        "        return \"\".join(map(str, map(int, boolarray)))\n",
        "    return f"
      ],
      "metadata": {
        "id": "xJzF9itmqquh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_functions(k, L, num_dimensions=400, min_threshold=0, max_threshold=255):\n",
        "    functions = []\n",
        "    for i in range(L):\n",
        "        dimensions = np.random.randint(low = 0, \n",
        "                                   high = num_dimensions,\n",
        "                                   size = k)\n",
        "        thresholds = np.random.randint(low = min_threshold, \n",
        "                                   high = max_threshold + 1, \n",
        "                                   size = k)\n",
        "\n",
        "        functions.append(create_function(dimensions, thresholds))\n",
        "    return functions"
      ],
      "metadata": {
        "id": "R1duQrrzqzF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hash_vector(functions, v):\n",
        "    return np.array([f(v) for f in functions])"
      ],
      "metadata": {
        "id": "R5e5cDdcq8IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hash_data(functions, A):\n",
        "    return np.array(list(map(lambda v: hash_vector(functions, v), A)))\n"
      ],
      "metadata": {
        "id": "aKZKBCBwq_z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_candidates(hashed_A, hashed_point, query_index):\n",
        "    return filter(lambda i: i != query_index and \\\n",
        "        any(hashed_point == hashed_A[i]), range(len(hashed_A)))\n"
      ],
      "metadata": {
        "id": "LZqXL56jrD8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lsh_setup(A, k = 24, L = 10):\n",
        "    functions = create_functions(k = k, L = L)\n",
        "    hashed_A = hash_data(functions, A)\n",
        "    return (functions, hashed_A)"
      ],
      "metadata": {
        "id": "UtHh32hfrJAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lsh_search(A, hashed_A, functions, query_index, num_neighbors = 10):\n",
        "    hashed_point = hash_vector(functions, A[query_index, :])\n",
        "    candidate_row_nums = get_candidates(hashed_A, hashed_point, query_index)\n",
        "    \n",
        "    distances = map(lambda r: (r, l1(A[r], A[query_index])), candidate_row_nums)\n",
        "    best_neighbors = sorted(distances, key=lambda t: t[1])[:num_neighbors]\n",
        "\n",
        "    return [t[0] for t in best_neighbors]"
      ],
      "metadata": {
        "id": "amnmZLcqrOsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(A, row_nums, base_filename):\n",
        "    for row_num in row_nums:\n",
        "        patch = np.reshape(A[row_num, :], [20, 20])\n",
        "        im = Image.fromarray(patch)\n",
        "        if im.mode != 'RGB':\n",
        "            im = im.convert('RGB')\n",
        "        im.save(base_filename + \"-\" + str(row_num) + \".png\")"
      ],
      "metadata": {
        "id": "KSf5r4KgrRpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_search(A, query_index, num_neighbors):\n",
        "    distances=  ( (r, l1(A[r], A[query_index])) for r in   range(len(A))  if r != query_index )\n",
        "    best_neighbors = sorted(distances, key=lambda t: t[1])[:num_neighbors]\n",
        "    \n",
        "    return [t[0] for t in best_neighbors]"
      ],
      "metadata": {
        "id": "h0revG-1rWOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "\n",
        "def measure_error(A,query_index,lsh_result: np.ndarray,linear_result:np.ndarray):\n",
        "    def sub_measure(result): \n",
        "        return reduce(lambda a,b: a+b,\n",
        "                      map(lambda r:  l1(A[r],A[query_index]),result),0. )\n",
        "   \n",
        "    return sub_measure(lsh_result)/sub_measure(linear_result)"
      ],
      "metadata": {
        "id": "wd8yoVLsrZFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_error_change(file_path):   \n",
        "    A= load_data(file_path)\n",
        "    def geterror(k=24,L =10):\n",
        "        error =0.\n",
        "        functions, hashed_A = lsh_setup(A, k = k, L = L)\n",
        "        for query_index in range(100,1100,100):\n",
        "            lsh_result =  lsh_search(A, hashed_A, functions, query_index, num_neighbors = 3)\n",
        "            linear_result =  linear_search( A,query_index,num_neighbors=3)\n",
        "            error += measure_error(A,query_index,lsh_result,linear_result)\n",
        "        return error/10\n",
        "        plot(A,lsh_result,'LSH')\n",
        "        plot(A,linear_result,'LINEAR')  \n",
        "        plot(A,[100],'RAW')\n",
        "    \n",
        "  \n",
        "    x_L= range(10,22,2)\n",
        "    x_K= range(16,26,2)\n",
        "    y_L= [ geterror(L=l)  for l in x_L ]\n",
        "    y_K= [geterror(k=k)  for k in x_K  ]\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.title('K=24')\n",
        "    plt.xlabel(\"L\")\n",
        "    plt.ylabel(\"error\")\n",
        "    plt.plot(x_L,y_L)\n",
        "    \n",
        "    plt.subplot(2,1,2)\n",
        "    plt.title('L=10')\n",
        "    plt.xlabel(\"K\")\n",
        "    plt.ylabel(\"error\")\n",
        "    plt.plot(x_K,y_K)\n",
        "    plt.show()\n",
        "    return (y_L,y_K)\n",
        "    \n"
      ],
      "metadata": {
        "id": "BKWU_drUrdfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def problem4():\n",
        "    y_L ,y_K  =  plot_error_change ('/content/sample_data/patches.csv') \n",
        "    return  y_L ,y_K "
      ],
      "metadata": {
        "id": "AKymalC_r-Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestLSH(unittest.TestCase):\n",
        "    def test_l1(self):\n",
        "        u = np.array([1, 2, 3, 4])\n",
        "        v = np.array([2, 3, 2, 3])\n",
        "        self.assertEqual(l1(u, v), 4)\n",
        "\n",
        "    def test_hash_data(self):\n",
        "        f1 = lambda v: sum(v)\n",
        "        f2 = lambda v: sum([x * x for x in v])\n",
        "        A = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "        self.assertEqual(f1(A[0,:]), 6)\n",
        "        self.assertEqual(f2(A[0,:]), 14)\n",
        "\n",
        "        functions = [f1, f2]\n",
        "        self.assertTrue(np.array_equal(hash_vector(functions, A[0, :]), np.array([6, 14])))\n",
        "        self.assertTrue(np.array_equal(hash_data(functions, A), np.array([[6, 14], [15, 77]])))\n",
        "        if __name__ == '__main__':\n",
        "          problem4() \n",
        "           \n"
      ],
      "metadata": {
        "id": "ci4xxDcnyylZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}